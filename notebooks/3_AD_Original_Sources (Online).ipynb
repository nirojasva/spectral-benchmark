{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38DOsgezOTWG"
   },
   "source": [
    "# Individual Analysis of Online Anomaly Detectors with PV Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "params = {\n",
    "    'font.size': 12,           \n",
    "    'axes.labelsize': 12,      \n",
    "    'xtick.labelsize': 10,      \n",
    "    'ytick.labelsize': 10,      \n",
    "    'legend.fontsize': 10,      \n",
    "    'figure.titlesize': 12\n",
    "}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.dates as mdates\n",
    "from pathlib import Path\n",
    "import re\n",
    "from sklearn.metrics import roc_auc_score, auc, precision_recall_curve, roc_curve\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DEFAULT_PARAMS_FIXED_WINDOW = pd.array([\"HStree_120_{'anomaly_threshold': 0.5, 'max_depth': 15, 'number_of_trees': 25, 'size_limit': 0.1}\",\n",
    "       \"xStream_120_{'depth': 25, 'n_chains': 100, 'num_components': 100}\",\n",
    "       \"RSHash_120_{'decay': 0.015, 'feature_maxes': [10000], 'feature_mins': [0], 'num_components': 100, 'num_hash_fns': 1}\",\n",
    "       \"ExactStorm_120_{'max_radius': 0.1}\",\n",
    "       \"RobustRandomCutForest_120_{'num_trees': 4, 'tree_size': 256}\",\n",
    "       \"OnlineBootKNN_120_{'algorithm': 'brute', 'alpha': 0.05, 'chunk_size': 240, 'dmetric': 'cityblock', 'ensemble_size': 240, 'n_jobs': -1, 'transf': 'ZNORM'}\",\n",
    "       \"oIF_120_{'growth_criterion': 'adaptive', 'max_leaf_samples': 32, 'n_jobs': -1, 'num_trees': 32}\",\n",
    "       \"IForestASD_120_{'initial_window_X': None}\",\n",
    "       \"KitNet_120_{'hidden_ratio': 0.75, 'learning_rate': 0.1, 'max_size_ae': 10}\"],\n",
    "      dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DEFAULT_PARAMS_NO_FIXED_WINDOW = pd.array([\"HStree_60_{'anomaly_threshold': 0.5, 'max_depth': 15, 'number_of_trees': 25, 'size_limit': 0.1}\",\n",
    "       \"xStream_60_{'depth': 25, 'n_chains': 100, 'num_components': 100}\",\n",
    "       \"RSHash_120_{'decay': 0.015, 'feature_maxes': [10000], 'feature_mins': [0], 'num_components': 100, 'num_hash_fns': 1}\",\n",
    "       \"ExactStorm_120_{'max_radius': 0.1}\",\n",
    "       \"OnlineBootKNN_120_{'algorithm': 'brute', 'alpha': 0.05, 'chunk_size': 240, 'dmetric': 'cityblock', 'ensemble_size': 240, 'n_jobs': -1, 'transf': 'ZNORM'}\",\n",
    "       \"RobustRandomCutForest_240_{'num_trees': 4, 'tree_size': 256}\",\n",
    "       \"oIF_240_{'growth_criterion': 'adaptive', 'max_leaf_samples': 32, 'n_jobs': -1, 'num_trees': 32}\",\n",
    "       \"IForestASD_240_{'initial_window_X': None}\",\n",
    "       \"KitNet_240_{'hidden_ratio': 0.75, 'learning_rate': 0.1, 'max_size_ae': 10}\"],\n",
    "      dtype=object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS=DEFAULT_PARAMS_NO_FIXED_WINDOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the first number after the underscore for each element in PARAMS\n",
    "WINDOW_LIST = np.unique([re.search(r'_(\\d+)_', param).group(1) for param in PARAMS])\n",
    "\n",
    "print(WINDOW_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the path to the current script\n",
    "current_dir = Path.cwd()\n",
    "\n",
    "# Go one level up\n",
    "current_dir = current_dir.parent\n",
    "\n",
    "DATA_PATH = current_dir / 'datasets' / 'processed'\n",
    "\n",
    "# Define dataset paths\n",
    "dataset_paths = [\n",
    "    DATA_PATH / 'processed_server22_A1',\n",
    "    DATA_PATH / 'processed_server22_A2',\n",
    "    DATA_PATH / 'processed_server22_A3',\n",
    "    DATA_PATH / 'processed_server21_A4',\n",
    "    DATA_PATH / 'processed_server21_A5',\n",
    "    DATA_PATH / 'processed_L40S02_A6',\n",
    "    DATA_PATH / 'processed_server18_A7',\n",
    "    DATA_PATH / 'processed_server18_A8',\n",
    "    DATA_PATH / 'processed_server18_A9',\n",
    "]\n",
    "\n",
    "# Define dataset paths\n",
    "dataset_paths = [\n",
    "    DATA_PATH / 'processed_L40S02_A6',\n",
    "\n",
    "]\n",
    "\n",
    "def process_file(file_path, scenario):\n",
    "    try:\n",
    "        print(f\"Processing file: {file_path.name} for scenario: {scenario}\") # Now printing the scenario\n",
    "        df = pd.read_excel(file_path)\n",
    "        df[\"window_size\"] = file_path.name.split(\"_\")[-1].replace(\".xlsx\", \"\")\n",
    "        df[\"method_window_and_param\"] = df.method + \"_\" + df.window_size + \"_\" + df.param\n",
    "        df = df[df['method_window_and_param'].isin(PARAMS)]\n",
    "\n",
    "        # Example: Add a 'scenario' column to the DataFrame\n",
    "        df['scenario'] = scenario\n",
    "\n",
    "        return df if not df.empty else None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path.name}: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_path(path):\n",
    "    SCENARIO = path.name.split(\"_\")[-1]\n",
    "    print(f\"Processing path: {path.name}\")\n",
    "    if not path.is_dir():\n",
    "        return []\n",
    "    \n",
    "    files = [f for f in path.iterdir() if f.suffix == '.xlsx' and f.name.startswith('A')]\n",
    "    print(f\"Total Files for the Scenario {SCENARIO}: {len(files)}\")\n",
    "    \n",
    "    dfs = []\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(process_file, file, SCENARIO) for file in files]\n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            if result is not None:\n",
    "                dfs.append(result)\n",
    "    return dfs\n",
    "\n",
    "# Main execution\n",
    "all_dfs = []\n",
    "for dataset_path in dataset_paths:\n",
    "    all_dfs.extend(process_path(dataset_path))\n",
    "\n",
    "# Concatenate all DataFrames at once\n",
    "concatenated_df = pd.concat(all_dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENARIO = concatenated_df['scenario'].unique()[0] \n",
    "SCENARIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df[\"timestamp\"] = pd.to_datetime(concatenated_df[\"timestamp\"])\n",
    "concatenated_df[\"cleaned_score\"] = concatenated_df[\"cleaned_score\"].astype('float64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_filter = r\"OnlineBootMGV|LODA|Py\"\n",
    "filtered_data = concatenated_df[~concatenated_df['method'].str.contains(regex_filter, regex=True)]\n",
    "#filtered_data = filtered_data[filtered_data['method'].str.contains(\"std_p\")]\n",
    "#filtered_data = filtered_data[filtered_data['method'].str.contains(\"None|FOD|SOD|DIL|QUANT\")]\n",
    "#filtered_data = filtered_data[filtered_data['method'].str.contains(\"QUANT\")]\n",
    "#filtered_data = filtered_data[filtered_data.method.str.contains(\"OnlineBootGP|OnlineBootKNN\")]\n",
    "\n",
    "filtered_data[\"timestamp\"] = pd.to_datetime(filtered_data[\"timestamp\"])\n",
    "filtered_data[\"cleaned_score\"] = filtered_data[\"cleaned_score\"].astype('float64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the final list of unique merged combinations\n",
    "methods = filtered_data.method.unique()\n",
    "methods = ['IForestASD', 'KitNet', 'oIF', 'RobustRandomCutForest' ,'xStream', 'HStree',\n",
    " 'RSHash' ,'ExactStorm' ,'OnlineBootKNN']\n",
    "print(methods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the final list of unique merged combinations\n",
    "\n",
    "method_window_and_param = filtered_data[\"method_window_and_param\"].unique()\n",
    "print(method_window_and_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_colors = len(method_window_and_param)\n",
    "print(\"Total Hyperparameter Tuning: \", num_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#methods = np.array(['RSHash', 'RobustRandomCutForest', 'KitNet', 'ExactStorm', 'IForestASD', 'oIF', 'HStree', 'OnlineBootKNN','xStream'], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a color list (consider using a color palette from seaborn or matplotlib)\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "\n",
    "\n",
    "# Generate a list of colors corresponding to the methods\n",
    "color_list = [colors[i] for i in range(num_colors)]\n",
    "\n",
    "print(color_list)  # Display the first 10 colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the summary of cleaned process to the score\n",
    "filtered_data['error_type_score'] = filtered_data['error_type_score'].fillna(\"No Error\")\n",
    "filtered_data.pivot_table(index='method', columns='error_type_score', values='cleaned_score', aggfunc='count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = filtered_data[\"iteration\"].unique()[0:10]\n",
    "iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Score of Online Anomaly Detectors with Pfeiffer Vacuum Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by method and timestamp, calculating both the mean and std\n",
    "average_results = filtered_data.groupby(['method',  'timestamp'], as_index=False).agg(\n",
    "    mean_score=('cleaned_score', 'mean'),\n",
    "    std_score=('cleaned_score', 'std'),\n",
    "    mean_gt=('ground_truth', 'mean')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through methods and plot the averaged values and std\n",
    "for m, color in zip(methods, color_list):\n",
    "    # Create a single figure\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Filter data for the current method\n",
    "    method_data = average_results[(average_results[\"method\"] == m)]\n",
    "    \n",
    "    # Plot the mean score\n",
    "    ax1.plot(\n",
    "        method_data['timestamp'], \n",
    "        method_data['mean_score'], \n",
    "        label=f'{m} (Averaged Iterations) with Param', \n",
    "        color=color\n",
    "    )\n",
    "    \n",
    "    # Plot the standard deviation as a shaded area on the first axis\n",
    "    ax1.fill_between(\n",
    "        method_data['timestamp'], \n",
    "        method_data['mean_score'] - method_data['std_score'], \n",
    "        method_data['mean_score'] + method_data['std_score'], \n",
    "        color=color, alpha=0.3, label=f'Method {m} (Â± Std Dev)'\n",
    "    )\n",
    "\n",
    "    # Set labels and title for the first y-axis\n",
    "    ax1.set_xlabel('Time')\n",
    "    ax1.set_ylabel('Average Score in Time')\n",
    "    ax1.set_title(f\"Method {m} Score\")\n",
    "    \n",
    "    # Create a second y-axis\n",
    "    ax2 = ax1.twinx()\n",
    "    \n",
    "    # Plot the Ground Truth on the second y-axis\n",
    "    ax2.plot(\n",
    "        method_data['timestamp'], \n",
    "        method_data['mean_gt'], \n",
    "        label='Ground Truth', \n",
    "        color='grey', linestyle='--',\n",
    "        linewidth=0.9  # Make the line very thin\n",
    "    )\n",
    "    \n",
    "    # Set label for the second y-axis\n",
    "    ax2.set_ylabel('Ground Truth')\n",
    "    \n",
    "    # Adjust the second y-axis range (this is the key part to scale it visually)\n",
    "    ax2.set_ylim(0, 1.01)  # Scale the ground truth values down (50% here)\n",
    "\n",
    "    # Add legends and grid\n",
    "    ax1.legend(loc='upper left')\n",
    "    ax2.legend(loc='upper right')\n",
    "    ax1.grid(False)  # Remove gridlines\n",
    "    \n",
    "    # Format the x-axis to show only the hours\n",
    "    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "    # Improve layout and display\n",
    "    ax1.tick_params(axis='x')  # larger x-axis labels\n",
    "\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig(current_dir / 'notebooks' / 'score_functions'/ f\"{SCENARIO}_score_{m}.pdf\", format=\"pdf\")\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for m, color in zip(methods, color_list):\n",
    "    # Plot ROC Curve\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    f_method_data = filtered_data[filtered_data['method'] == m]\n",
    "    \n",
    "    for i in f_method_data['iteration'].unique():\n",
    "        \n",
    "        print(f\"Method: {m}, Iteration: {i}\")\n",
    "        # Filter data for the current method and iteration\n",
    "        method_data = f_method_data[f_method_data['iteration'] == i]\n",
    "\n",
    "        # Get true labels and scores\n",
    "        y_true = method_data['ground_truth'].values\n",
    "        y_scores = method_data['cleaned_score'].values\n",
    "\n",
    "        # Compute ROC curve and AUC\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        # Compute Precision-Recall curve and AUC\n",
    "        precision, recall, _ = precision_recall_curve(y_true, y_scores)\n",
    "        pr_auc = auc(recall, precision)\n",
    "\n",
    "\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(fpr, tpr, color=color, lw=1 + i * 0.5, label=f'ROC (AUC = {roc_auc:.3f}) Iteration {i}')\n",
    "\n",
    "\n",
    "        plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'ROC Curve for {m}')\n",
    "        plt.legend(loc='lower right')\n",
    "\n",
    "        # Plot Precision-Recall Curve\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(recall, precision, color=color, lw=1 + i * 0.5, label=f'PR (AUC = {pr_auc:.3f}) Iteration {i}')\n",
    "\n",
    "\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title(f'Precision-Recall Curve for {m}')\n",
    "        plt.legend(loc='lower left')\n",
    "\n",
    "        plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Training Time of Online Anomaly Detectors with PV Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single figure\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Group data by method and timestamp, calculating mean and standard deviation across iterations\n",
    "grouped_data = filtered_data.groupby(['method', 'timestamp']).agg(\n",
    "    mean_training_time_t=('training_time', 'mean'),\n",
    "    std_training_time_t=('training_time', 'std')\n",
    ").reset_index()\n",
    "\n",
    "# Loop through methods and plot the accumulated values with shaded area\n",
    "for m, color in zip(methods, color_list):\n",
    "    \n",
    "    method_data = grouped_data[grouped_data[\"method\"] == m]\n",
    "\n",
    "    # Compute cumulative sum\n",
    "    cumulative_training_time = method_data['mean_training_time_t'].expanding().sum()\n",
    "\n",
    "    # Plot averaged training time with accumulation\n",
    "    plt.plot(\n",
    "        range(len(method_data['timestamp'])),  # Use the index as x-axis\n",
    "        cumulative_training_time,\n",
    "        label=f'{m}',\n",
    "        color=color\n",
    "    )\n",
    "\n",
    "    # Plot shaded area representing standard deviation\n",
    "    plt.fill_between(\n",
    "        range(len(method_data['timestamp'])),  # Use the index as x-axis\n",
    "        (method_data['mean_training_time_t'] - method_data['std_training_time_t']).expanding().sum(),\n",
    "        (method_data['mean_training_time_t'] + method_data['std_training_time_t']).expanding().sum(),\n",
    "        color=color,\n",
    "        alpha=0.2\n",
    "    )\n",
    "\n",
    "    # Get max accumulated training time and timestamp\n",
    "    max_time = cumulative_training_time.max()\n",
    "\n",
    "    max_timestamp = len(method_data['timestamp'])  # Ensuring correct index\n",
    "\n",
    "    # Format the max value properly\n",
    "    formatted_max_time = f\"{max_time:,.2f}\"  # Adds commas and rounds to 2 decimals\n",
    "\n",
    "    if m in [\"OnlineBootKNN\", \"xStream\", \"KitNet\"]:\n",
    "        # Annotate the max value\n",
    "        plt.annotate(\n",
    "            f'Max: {formatted_max_time}', \n",
    "            xy=(max_timestamp, max_time), \n",
    "            xytext=(max_timestamp, max_time * 1.03),  # Adjusted for better visibility\n",
    "            #arrowprops=dict(facecolor=color, arrowstyle='->'),\n",
    "            color=color,\n",
    "            ha='center'\n",
    "        )\n",
    "\n",
    "# Format the x-axis to show only the hours\n",
    "# plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "    \n",
    "# Adding labels and title\n",
    "#plt.title(\"Training Time\", fontsize=FONTSIZE_SEC)\n",
    "plt.xlabel('# Instances')\n",
    "plt.ylabel('Accumulative Training Time in Seconds')\n",
    "plt.legend(loc='upper left')  # Place legend dynamically\n",
    "plt.xticks(rotation=45)\n",
    "#plt.grid(True, linestyle='--', alpha=0.6)  # Improve grid visibility\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(current_dir / 'notebooks' / 'img_training_and_scoring_time'/f\"{SCENARIO}_accum_training_time.pdf\", format=\"pdf\")\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single figure\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Group data by method and timestamp, calculating mean and standard deviation across iterations\n",
    "grouped_data = filtered_data.groupby(['method', 'timestamp']).agg(\n",
    "    mean_training_time_t=('training_time', 'mean'),\n",
    "    std_training_time_t=('training_time', 'std')\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "for m, color in zip(methods, color_list):\n",
    "    \n",
    "    method_data = grouped_data[grouped_data[\"method\"] == m]\n",
    "\n",
    "    \n",
    "    training_time = method_data['mean_training_time_t']\n",
    "\n",
    "    # Plot averaged training time \n",
    "    plt.plot(\n",
    "        method_data['timestamp'],\n",
    "        training_time,\n",
    "        label=f'{m}',\n",
    "        color=color\n",
    "    )\n",
    "\n",
    "    # Plot shaded area representing standard deviation\n",
    "    plt.fill_between(\n",
    "        method_data['timestamp'],\n",
    "        (method_data['mean_training_time_t'] - method_data['std_training_time_t']),\n",
    "        (method_data['mean_training_time_t'] + method_data['std_training_time_t']),\n",
    "        color=color,\n",
    "        alpha=0.2\n",
    "    )\n",
    "\n",
    "    \n",
    "    max_time = training_time.max()\n",
    "    max_idx = training_time.idxmax()\n",
    "    max_timestamp = method_data.loc[max_idx, 'timestamp']  # Ensuring correct index\n",
    "\n",
    "    # Format the max value properly\n",
    "    formatted_max_time = f\"{max_time:,.2f}\"  # Adds commas and rounds to 2 decimals\n",
    "\n",
    "    # Annotate the max value\n",
    "    plt.annotate(\n",
    "        f'Max: {formatted_max_time}', \n",
    "        xy=(max_timestamp, max_time), \n",
    "        xytext=(max_timestamp, max_time * 1.03),  # Adjusted for better visibility\n",
    "        #arrowprops=dict(facecolor=color, arrowstyle='->'),\n",
    "        color=color,\n",
    "        ha='center'\n",
    "    )\n",
    "# Format the x-axis to show only the hours\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "# Adding labels and title\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Training Time in Seconds')\n",
    "plt.legend(loc='best')  # Place legend dynamically\n",
    "plt.title(\"Training Time\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)  # Improve grid visibility\n",
    "plt.tight_layout()\n",
    "\n",
    "#plt.savefig(f\"/home/nicolas/spectral_anomaly_detector/notebooks/img_training_and_scoring_time/{SCENARIO}_training_time.png\", format=\"png\")\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by method and compute training time statistics\n",
    "training_time_stats = filtered_data.groupby(['method', 'timestamp'])['training_time'].agg(\n",
    "    mean_training_time_t='mean',\n",
    ").reset_index()\n",
    "\n",
    "training_time_stats = training_time_stats.groupby(['method'])['mean_training_time_t'].agg(\n",
    "    mean_time='mean',\n",
    "    median_time='median',\n",
    "    min_time='min',\n",
    "    max_time='max',\n",
    "    std_dev_time='std'\n",
    ").reset_index()\n",
    "\n",
    "# Sort by mean training time in ascending order\n",
    "training_time_stats = training_time_stats.sort_values(by='mean_time', ascending=True)\n",
    "\n",
    "# Display summary\n",
    "training_time_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Scoring Time of Online Anomaly Detectors with PV Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single figure\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Group data by method and timestamp, calculating mean and standard deviation across iterations\n",
    "grouped_data = filtered_data.groupby(['method', 'timestamp']).agg(\n",
    "    mean_scoring_time_t=('scoring_time', 'mean'),\n",
    "    std_scoring_time_t=('scoring_time', 'std')\n",
    ").reset_index()\n",
    "\n",
    "# Loop through methods and plot the accumulated values with shaded area\n",
    "for m, color in zip(methods, color_list):\n",
    "    \n",
    "    method_data = grouped_data[grouped_data[\"method\"] == m]\n",
    "\n",
    "    # Compute cumulative sum\n",
    "    cumulative_training_time = method_data['mean_scoring_time_t'].expanding().sum()\n",
    "\n",
    "    # Plot averaged training time with accumulation\n",
    "    plt.plot(\n",
    "        range(len(method_data['timestamp'])),  # Use the index as x-axis\n",
    "        cumulative_training_time,\n",
    "        label=f'{m}',\n",
    "        color=color\n",
    "    )\n",
    "\n",
    "    # Plot shaded area representing standard deviation\n",
    "    plt.fill_between(\n",
    "        range(len(method_data['timestamp'])),  # Use the index as x-axis\n",
    "        (method_data['mean_scoring_time_t'] - method_data['std_scoring_time_t']).expanding().sum(),\n",
    "        (method_data['mean_scoring_time_t'] + method_data['std_scoring_time_t']).expanding().sum(),\n",
    "        color=color,\n",
    "        alpha=0.2\n",
    "    )\n",
    "\n",
    "    # Get max accumulated training time and timestamp\n",
    "    max_time = cumulative_training_time.max()\n",
    "\n",
    "    max_timestamp = len(method_data['timestamp'])  # Ensuring correct index\n",
    "\n",
    "    # Format the max value properly\n",
    "    formatted_max_time = f\"{max_time:,.2f}\"  # Adds commas and rounds to 2 decimals\n",
    "\n",
    "    if m in [\"OnlineBootKNN\", \"xStream\", \"KitNet\"]:\n",
    "        # Annotate the max value\n",
    "        plt.annotate(\n",
    "            f'Max: {formatted_max_time}', \n",
    "            xy=(max_timestamp, max_time), \n",
    "            xytext=(max_timestamp, max_time * 1.03),  # Adjusted for better visibility\n",
    "            #arrowprops=dict(facecolor=color, arrowstyle='->'),\n",
    "            color=color,\n",
    "            ha='center'\n",
    "        )\n",
    "\n",
    "# Format the x-axis to show only the hours\n",
    "# plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "    \n",
    "# Adding labels and title\n",
    "#plt.title(\"Scoring Time\", fontsize=FONTSIZE_SEC)\n",
    "plt.xlabel('# Instances')\n",
    "plt.ylabel('Accumulative Scoring Time in Seconds')\n",
    "plt.legend(loc='upper left')  # Place legend dynamically\n",
    "plt.xticks(rotation=45)\n",
    "#plt.grid(True, linestyle='--', alpha=0.6)  # Improve grid visibility\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(current_dir / 'notebooks' / 'img_training_and_scoring_time'/ f\"{SCENARIO}_accum_scoring_time.pdf\", format=\"pdf\")\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single figure\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Group data by method and timestamp, calculating mean and standard deviation across iterations\n",
    "grouped_data = filtered_data.groupby(['method', 'timestamp']).agg(\n",
    "    mean_scoring_time_t=('scoring_time', 'mean'),\n",
    "    std_scoring_time_t=('scoring_time', 'std')\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "for m, color in zip(methods, color_list):\n",
    "    \n",
    "    method_data = grouped_data[grouped_data[\"method\"] == m]\n",
    "\n",
    "    scoring_time = method_data['mean_scoring_time_t']\n",
    "\n",
    "    plt.plot(\n",
    "        method_data['timestamp'],\n",
    "        scoring_time,\n",
    "        label=f'{m}',\n",
    "        color=color\n",
    "    )\n",
    "\n",
    "    # Plot shaded area representing standard deviation\n",
    "    plt.fill_between(\n",
    "        method_data['timestamp'],\n",
    "        (method_data['mean_scoring_time_t'] - method_data['std_scoring_time_t']),\n",
    "        (method_data['mean_scoring_time_t'] + method_data['std_scoring_time_t']),\n",
    "        color=color,\n",
    "        alpha=0.2\n",
    "    )\n",
    "\n",
    "    \n",
    "    max_time = scoring_time.max()\n",
    "    max_idx = scoring_time.idxmax()\n",
    "    max_timestamp = method_data.loc[max_idx, 'timestamp']  # Ensuring correct index\n",
    "\n",
    "    # Format the max value properly\n",
    "    formatted_max_time = f\"{max_time:,.2f}\"  # Adds commas and rounds to 2 decimals\n",
    "\n",
    "    # Annotate the max value\n",
    "    plt.annotate(\n",
    "        f'Max: {formatted_max_time}', \n",
    "        xy=(max_timestamp, max_time), \n",
    "        xytext=(max_timestamp, max_time * 1.03),  # Adjusted for better visibility\n",
    "        #arrowprops=dict(facecolor=color, arrowstyle='->'),\n",
    "        color=color,\n",
    "        ha='center'\n",
    "    )\n",
    "# Format the x-axis to show only the hours\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "# Adding labels and title\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Scoring Time in Seconds')\n",
    "plt.legend(loc='best')  # Place legend dynamically\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)  # Improve grid visibility\n",
    "plt.tight_layout()\n",
    "plt.title(\"Scoring Time\")\n",
    "#plt.savefig(f\"/home/nicolas/spectral_anomaly_detector/notebooks/img_training_and_scoring_time/{SCENARIO}_scoring_time.png\", format=\"png\")\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by method and compute scoring time statistics\n",
    "scoring_time_stats = filtered_data.groupby(['method', 'timestamp'])['scoring_time'].agg(\n",
    "    mean_scoring_time_t='mean',\n",
    ").reset_index()\n",
    "\n",
    "scoring_time_stats = scoring_time_stats.groupby(['method'])['mean_scoring_time_t'].agg(\n",
    "    mean_time='mean',\n",
    "    median_time='median',\n",
    "    min_time='min',\n",
    "    max_time='max',\n",
    "    std_dev_time='std'\n",
    ").reset_index()\n",
    "\n",
    "# Sort by mean scoring time in ascending order\n",
    "scoring_time_stats = scoring_time_stats.sort_values(by='mean_time', ascending=True)\n",
    "\n",
    "# Display summary\n",
    "scoring_time_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data['total_time']=filtered_data['training_time']+filtered_data['scoring_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filtered_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m style_cycler \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mcycle(\u001b[38;5;28mzip\u001b[39m(line_styles, markers))\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m4.5\u001b[39m)) \n\u001b[0;32m----> 8\u001b[0m grouped_data \u001b[38;5;241m=\u001b[39m \u001b[43mfiltered_data\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39magg(\n\u001b[1;32m      9\u001b[0m     mean_total_time_t\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_time\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     10\u001b[0m     std_total_time_t\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_time\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m )\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m, color \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(methods, color_list):\n\u001b[1;32m     15\u001b[0m     ls, mk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(style_cycler)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'filtered_data' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x450 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# --- 1. SETUP PUBLICATION STYLE ---\n",
    "# Set the font sizes to match the document (10pt main, >7pt for small text)\n",
    "params = {\n",
    "    'font.size': 10,              # Main text size\n",
    "    'axes.labelsize': 10,         # X/Y Label size\n",
    "    'axes.titlesize': 10,         # Title size\n",
    "    'xtick.labelsize': 8,         # Tick size (slightly smaller, but >7pt)\n",
    "    'ytick.labelsize': 8,         # Tick size\n",
    "    'legend.fontsize': 8,         # Legend size\n",
    "    'figure.titlesize': 12,\n",
    "    'lines.linewidth': 1.5,\n",
    "    'lines.markersize': 6,\n",
    "    'font.family': 'serif',       # Matches standard academic papers (Times/LaTeX)\n",
    "    'text.usetex': False          # Set to True if you have LaTeX installed for math rendering\n",
    "}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "# Define distinct styles for grayscale safety\n",
    "line_styles = ['-', '--', '-.', ':', (0, (3, 1, 1, 1)), (0, (5, 10)), (0, (1, 1))]\n",
    "markers = ['o', 's', '^', 'v', 'D', 'X', '*']\n",
    "style_cycler = itertools.cycle(zip(line_styles, markers))\n",
    "\n",
    "# --- 2. DATA PROCESSING (Assumed from your snippet) ---\n",
    "# Assuming 'filtered_data', 'methods', and 'color_list' exist in your environment.\n",
    "# grouped_data calculation remains the same:\n",
    "grouped_data = filtered_data.groupby(['method', 'timestamp']).agg(\n",
    "    mean_total_time_t=('total_time', 'mean'),\n",
    "    std_total_time_t=('total_time', 'std')\n",
    ").reset_index()\n",
    "\n",
    "# --- 3. PLOTTING ---\n",
    "# figsize=(7, 4.5) is standard for a full-width (2-column span) figure.\n",
    "# If this is for a single column, use figsize=(3.5, 2.5).\n",
    "plt.figure(figsize=(3.5, 2.5))\n",
    "\n",
    "for m, color in zip(methods, color_list):\n",
    "    \n",
    "    ls, mk = next(style_cycler)\n",
    "    method_data = grouped_data[grouped_data[\"method\"] == m]\n",
    "\n",
    "    # Compute cumulative sum\n",
    "    cumulative_training_time = method_data['mean_total_time_t'].expanding().sum()\n",
    "    \n",
    "    # Calculate error bands (cumulative error propagation approximation)\n",
    "    # Note: Standard deviation doesn't strictly sum linearly, but for viz this is common.\n",
    "    upper_bound = (method_data['mean_total_time_t'] + method_data['std_total_time_t']).expanding().sum()\n",
    "    lower_bound = (method_data['mean_total_time_t'] - method_data['std_total_time_t']).expanding().sum()\n",
    "\n",
    "    # Marker interval prevents cluttering the line\n",
    "    marker_interval = max(1, len(method_data) // 10)\n",
    "\n",
    "    plt.plot(\n",
    "        range(len(method_data['timestamp'])), \n",
    "        cumulative_training_time,\n",
    "        label=f'{m}',\n",
    "        color=color,\n",
    "        linestyle=ls,       \n",
    "        marker=mk,          \n",
    "        markevery=marker_interval, \n",
    "        markersize=6,       \n",
    "        linewidth=1.5       \n",
    "    )\n",
    "\n",
    "    # Shaded error region\n",
    "    plt.fill_between(\n",
    "        range(len(method_data['timestamp'])), \n",
    "        lower_bound,\n",
    "        upper_bound,\n",
    "        color=color,\n",
    "        alpha=0.15,         \n",
    "        edgecolor=None      \n",
    "    )\n",
    "\n",
    "    # Annotations\n",
    "    max_time = cumulative_training_time.max()\n",
    "    max_timestamp = len(method_data['timestamp']) \n",
    "    formatted_max_time = f\"{max_time:,.2f}\"\n",
    "    \n",
    "    # Specific annotations for methods of interest\n",
    "    if m in [\"OnlineBootKNN\", \"xStream\", \"KitNet\"]:\n",
    "        plt.annotate(\n",
    "            f'Max: {formatted_max_time}', \n",
    "            xy=(max_timestamp, max_time), \n",
    "            # Offset text slightly to avoid overlapping the line end\n",
    "            xytext=(max_timestamp, max_time * 1.05), \n",
    "            color='black', \n",
    "            fontsize=8,        # Compliant: > 7pt\n",
    "            fontweight='bold',\n",
    "            ha='center',\n",
    "            # Add a white background to text so it's readable over grid lines\n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"none\", alpha=0.7)\n",
    "        )\n",
    "\n",
    "# --- 4. FORMATTING ---\n",
    "plt.xlabel('# Total Processed Instances')\n",
    "plt.ylabel('Accumulative Time (s)') \n",
    "\n",
    "# Grid is helpful for reading values in grayscale\n",
    "plt.grid(True, which='major', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "# Legend settings to ensure it fits\n",
    "plt.legend(loc='upper left', frameon=True, fontsize=8, fancybox=False, edgecolor='black')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Tight layout is crucial, but bbox_inches='tight' in savefig is safer\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save with bbox_inches='tight' to ensure no labels are cut off\n",
    "output_path = current_dir / 'notebooks' / 'img_training_and_scoring_time' / f\"{SCENARIO}_accum_total_time.pdf\"\n",
    "plt.savefig(output_path, format=\"pdf\", bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env_spectra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
